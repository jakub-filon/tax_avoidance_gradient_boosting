{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradient Boosting Models Exercise: Advanced Ensemble Methods\n",
        "\n",
        "**ML2 Course - Extra Points Assignment (5 points)**\n",
        "\n",
        "**Objective:**\n",
        "The goal of this exercise is to explore and master various gradient boosting algorithms for panel data modeling. You will implement and compare seven state-of-the-art boosting models that represent the cutting edge of machine learning regression techniques.\n",
        "\n",
        "**Models to Implement:**\n",
        "\n",
        "1. **AdaBoost** ([AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)) - Adaptive Boosting, the pioneering boosting algorithm\n",
        "2. **GBM** ([GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)) - Classic Gradient Boosting Machine from scikit-learn\n",
        "3. **GBM Histogram** ([HistGradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html)) - Histogram-based Gradient Boosting (faster, inspired by LightGBM)\n",
        "4. **XGBoost** ([XGBRegressor](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor)) - Extreme Gradient Boosting, industry standard\n",
        "5. **LightGBM** ([LGBMRegressor](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html)) - Light Gradient Boosting Machine, optimized for speed and memory\n",
        "6. **CatBoost** ([CatBoostRegressor](https://catboost.ai/en/docs/concepts/python-reference_catboostregressor)) - Categorical Boosting, handles categorical features natively\n",
        "7. **XGBoostLSS** ([XGBoostLSS](https://github.com/StatMixedML/XGBoostLSS)) - XGBoost for Location, Scale and Shape, probabilistic predictions\n",
        "\n",
        "**Tasks Workflow:**\n",
        "\n",
        "Following a similar process to the SVM / KNN model (`notebooks/07.knn-model.ipynb`):\n",
        "\n",
        "1. **Load the prepared training data** from the preprocessing step\n",
        "2. **Feature Engineering** (if necessary):\n",
        "   - Note: Tree-based models do NOT require standardization/normalization\n",
        "   - They are invariant to monotonic transformations of features\n",
        "3. **Feature Selection**:\n",
        "   - Use existing feature rankings from `feature_ranking.xlsx` for initial feature selection\n",
        "   - Consider feature importance from tree-based models\n",
        "   - Test multiple feature sets (top 20, 30, 50 features, etc.) - please utilize Feature Importance directly from models\n",
        "4. **Hyperparameter Tuning**: (2 points)\n",
        "   - Use GridSearchCV or RandomizedSearchCV, or Optuna\n",
        "   - Focus on key parameters: learning rate, boosting iterations, tree max depth, regularization (if applicable) etc. \n",
        "   - Use rolling window cross-validation to avoid data leakage\n",
        "5. **Identify Local Champions**: (1 point)\n",
        "   - Select the best model for each algorithm class\n",
        "   - Compare based on RMSE on validation sets\n",
        "6. **Save Models**:\n",
        "   - Pickle the best models for each algorithm\n",
        "   - Save to `../models/` directory\n",
        "\n",
        "**Important Notes:**\n",
        "\n",
        "- Gradient boosting models are powerful but prone to overfitting - pay attention to regularization\n",
        "- Learning rate and number of estimators have an inverse relationship\n",
        "- Early stopping can be used to prevent overfitting\n",
        "- XGBoostLSS provides distributional forecasts (not just point estimates)\n",
        "- Use time-series aware cross-validation (rolling window) for final model selection\n",
        "\n",
        "**Model Evaluation:** (2 points)\n",
        "\n",
        "After completing this notebook:\n",
        "- Load your models in `notebooks/09.final-comparison-and-summary.ipynb`\n",
        "- Compare them against existing models (OLS, ARMA, ARDL, KNN, SVR)\n",
        "- Check if any gradient boosting model becomes the new champion!\n",
        "\n",
        "---\n",
        "\n",
        "## Submission Requirements\n",
        "\n",
        "- Complete this notebook with code and outputs\n",
        "- Save best model(s) as pickle files in `models/` directory\n",
        "- Commit and push to your GitHub repository\n",
        "- Send repository link to: **mj.wozniak9@uw.edu.pl**\n",
        "\n",
        "**Deadline:** [To be announced by instructor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import warnings\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, ParameterGrid\n",
        "from xgboost import XGBRegressor, DMatrix\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboostlss.model import XGBoostLSS\n",
        "from xgboostlss.distributions.Gaussian import Gaussian\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 160)\n",
        "SEED = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3993, 115), (363, 115))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_DIR = Path(\"../data/output\")\n",
        "MODEL_DIR = Path(\"../models\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# I had to remove certain characters from feature names to make them fully compatible with all models\n",
        "def clean_feature_name(name: str) -> str:\n",
        "    if not isinstance(name, str):\n",
        "        return name\n",
        "    translation_table = str.maketrans({\"[\":\"\", \"]\":\"\", \"(\":\"\", \")\":\"\", \" \":\"\", \",\":\"\"})\n",
        "    return name.translate(translation_table)\n",
        "\n",
        "train_raw = pd.read_csv(DATA_DIR / \"train_fe.csv\", index_col=0)\n",
        "test_raw = pd.read_csv(DATA_DIR / \"test_fe.csv\", index_col=0)\n",
        "ranking_raw = pd.read_excel(DATA_DIR / \"feature_ranking.xlsx\").rename(columns={\"Unnamed: 0\": \"feature\"})\n",
        "\n",
        "train = train_raw.rename(columns=clean_feature_name).copy()\n",
        "test = test_raw.rename(columns=clean_feature_name).copy()\n",
        "ranking = ranking_raw.assign(feature=ranking_raw[\"feature\"].map(clean_feature_name))\n",
        "\n",
        "sort_cols = [col for col in [\"rok\", \"Ticker\"] if col in train.columns]\n",
        "if sort_cols:\n",
        "    train = train.sort_values(sort_cols).reset_index(drop=True)\n",
        "    test = test.sort_values(sort_cols).reset_index(drop=True)\n",
        "\n",
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique features selected: 56\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>etr_y_past</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>etr_y_ma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>diff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>ni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>pi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>intant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>intant_sqrt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>ta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>revenue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>roa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mi_score</td>\n",
              "      <td>roa_clip</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      metric      feature\n",
              "0   mi_score   etr_y_past\n",
              "1   mi_score     etr_y_ma\n",
              "2   mi_score          txt\n",
              "3   mi_score         diff\n",
              "4   mi_score           ni\n",
              "5   mi_score           pi\n",
              "6   mi_score       intant\n",
              "7   mi_score  intant_sqrt\n",
              "8   mi_score           ta\n",
              "9   mi_score      revenue\n",
              "10  mi_score          roa\n",
              "11  mi_score     roa_clip"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranking['corr_abs'] = ranking['corr'].abs()\n",
        "\n",
        "metric_tops = {\n",
        "    'mi_score': ranking.nlargest(20, 'mi_score')['feature'].tolist(),\n",
        "    'sign_fscore': ranking.nlargest(20, 'sign_fscore')['feature'].tolist(),\n",
        "    'corr_abs': ranking.nlargest(20, 'corr_abs')['feature'].tolist(),\n",
        "    'boruta_rank': ranking.loc[ranking['boruta_rank'].notna()].nsmallest(20, 'boruta_rank')['feature'].tolist(),\n",
        "}\n",
        "\n",
        "combined_features = sorted({feat for feats in metric_tops.values() for feat in feats})\n",
        "\n",
        "selected_features = [feat for feat in combined_features if feat in train.columns]\n",
        "\n",
        "summary_rows = []\n",
        "for metric, feats in metric_tops.items():\n",
        "    for feat in feats:\n",
        "        summary_rows.append({'metric': metric, 'feature': feat})\n",
        "feature_summary = pd.DataFrame(summary_rows)\n",
        "\n",
        "print(f\"Unique features selected: {len(selected_features)}\")\n",
        "feature_summary.head(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3993, 56), (363, 56))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TARGET = 'etr'\n",
        "\n",
        "base_features = selected_features.copy()\n",
        "X_train_full = train[base_features].copy()\n",
        "X_test_full = test[base_features].copy()\n",
        "\n",
        "y_train = train[TARGET].copy()\n",
        "y_test = test[TARGET].copy()\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "X_train_full.shape, X_test_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "RMSE_SCORER = 'neg_root_mean_squared_error'\n",
        "cv_leaderboard = []\n",
        "test_performance = []\n",
        "\n",
        "def run_grid_search(name, estimator, param_grid, X, y, n_jobs=-1):\n",
        "    grid = GridSearchCV(\n",
        "        estimator=estimator,\n",
        "        param_grid=param_grid,\n",
        "        scoring=RMSE_SCORER,\n",
        "        cv=tscv,\n",
        "        n_jobs=n_jobs,\n",
        "        verbose=0,\n",
        "        error_score='raise',\n",
        "        return_train_score=False,\n",
        "    )\n",
        "    grid.fit(X, y)\n",
        "    print(f\"{name}: best CV RMSE = {-grid.best_score_:.4f}\")\n",
        "    return grid\n",
        "\n",
        "def evaluate_on_test(name, model, X, y):\n",
        "    preds = model.predict(X)\n",
        "    rmse = float(np.sqrt(mean_squared_error(y, preds)))\n",
        "    mae = float(mean_absolute_error(y, preds))\n",
        "    print(f\"{name}: TEST RMSE={rmse:.4f} | MAE={mae:.4f}\")\n",
        "    return {'model': name, 'rmse': rmse, 'mae': mae}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "etr_y_ma      0.288166\n",
              "etr_y_past    0.132263\n",
              "diff          0.072477\n",
              "diff_ma       0.065042\n",
              "WB_GDPpc      0.039396\n",
              "txt           0.033265\n",
              "capex         0.025298\n",
              "rok           0.018998\n",
              "sale          0.018476\n",
              "diff_dta      0.017445\n",
              "dtype: float64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "importance_model = GradientBoostingRegressor(random_state=SEED)\n",
        "importance_model.fit(X_train_full, y_train)\n",
        "importances = pd.Series(importance_model.feature_importances_, index=base_features)\n",
        "feature_importances = importances.sort_values(ascending=False)\n",
        "feature_importances.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_set</th>\n",
              "      <th>num_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>top_20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>top_30</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>top_50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>top_all</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature_set  num_features\n",
              "0      top_20            20\n",
              "1      top_30            30\n",
              "2      top_50            50\n",
              "3     top_all            56"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_sets = {}\n",
        "for k in [20, 30, 50]:\n",
        "    k = min(k, len(feature_importances))\n",
        "    feature_sets[f'top_{k}'] = feature_importances.head(k).index.tolist()\n",
        "feature_sets['top_all'] = feature_importances.index.tolist()\n",
        "\n",
        "feature_set_summary = pd.DataFrame(\n",
        "    [(name, len(cols)) for name, cols in feature_sets.items()],\n",
        "    columns=['feature_set', 'num_features']\n",
        ").sort_values('num_features')\n",
        "feature_set_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Feature set: top_20 (20 features) ===\n",
            "AdaBoost: best CV RMSE = 0.1558\n",
            "AdaBoost: TEST RMSE=0.0925 | MAE=0.0678\n",
            "AdaBoost: best CV RMSE = 0.1558\n",
            "AdaBoost: TEST RMSE=0.0925 | MAE=0.0678\n",
            "GBM: best CV RMSE = 0.1491\n",
            "GBM: TEST RMSE=0.0800 | MAE=0.0542\n",
            "GBM: best CV RMSE = 0.1491\n",
            "GBM: TEST RMSE=0.0800 | MAE=0.0542\n",
            "HistGBM: best CV RMSE = 0.1488\n",
            "HistGBM: TEST RMSE=0.0803 | MAE=0.0546\n",
            "HistGBM: best CV RMSE = 0.1488\n",
            "HistGBM: TEST RMSE=0.0803 | MAE=0.0546\n",
            "XGBoost: best CV RMSE = 0.1509\n",
            "XGBoost: TEST RMSE=0.0795 | MAE=0.0540\n",
            "XGBoost: best CV RMSE = 0.1509\n",
            "XGBoost: TEST RMSE=0.0795 | MAE=0.0540\n",
            "LightGBM: best CV RMSE = 0.1488\n",
            "LightGBM: TEST RMSE=0.0807 | MAE=0.0553\n",
            "LightGBM: best CV RMSE = 0.1488\n",
            "LightGBM: TEST RMSE=0.0807 | MAE=0.0553\n",
            "CatBoost: best CV RMSE = 0.1501\n",
            "CatBoost: TEST RMSE=0.0786 | MAE=0.0536\n",
            "\n",
            "=== Feature set: top_30 (30 features) ===\n",
            "CatBoost: best CV RMSE = 0.1501\n",
            "CatBoost: TEST RMSE=0.0786 | MAE=0.0536\n",
            "\n",
            "=== Feature set: top_30 (30 features) ===\n",
            "AdaBoost: best CV RMSE = 0.1554\n",
            "AdaBoost: TEST RMSE=0.0916 | MAE=0.0660\n",
            "AdaBoost: best CV RMSE = 0.1554\n",
            "AdaBoost: TEST RMSE=0.0916 | MAE=0.0660\n",
            "GBM: best CV RMSE = 0.1486\n",
            "GBM: TEST RMSE=0.0806 | MAE=0.0544\n",
            "GBM: best CV RMSE = 0.1486\n",
            "GBM: TEST RMSE=0.0806 | MAE=0.0544\n",
            "HistGBM: best CV RMSE = 0.1489\n",
            "HistGBM: TEST RMSE=0.0798 | MAE=0.0545\n",
            "HistGBM: best CV RMSE = 0.1489\n",
            "HistGBM: TEST RMSE=0.0798 | MAE=0.0545\n",
            "XGBoost: best CV RMSE = 0.1513\n",
            "XGBoost: TEST RMSE=0.0805 | MAE=0.0543\n",
            "XGBoost: best CV RMSE = 0.1513\n",
            "XGBoost: TEST RMSE=0.0805 | MAE=0.0543\n",
            "LightGBM: best CV RMSE = 0.1497\n",
            "LightGBM: TEST RMSE=0.0810 | MAE=0.0555\n",
            "LightGBM: best CV RMSE = 0.1497\n",
            "LightGBM: TEST RMSE=0.0810 | MAE=0.0555\n",
            "CatBoost: best CV RMSE = 0.1505\n",
            "CatBoost: TEST RMSE=0.0804 | MAE=0.0541\n",
            "\n",
            "=== Feature set: top_50 (50 features) ===\n",
            "CatBoost: best CV RMSE = 0.1505\n",
            "CatBoost: TEST RMSE=0.0804 | MAE=0.0541\n",
            "\n",
            "=== Feature set: top_50 (50 features) ===\n",
            "AdaBoost: best CV RMSE = 0.1552\n",
            "AdaBoost: TEST RMSE=0.0943 | MAE=0.0696\n",
            "AdaBoost: best CV RMSE = 0.1552\n",
            "AdaBoost: TEST RMSE=0.0943 | MAE=0.0696\n",
            "GBM: best CV RMSE = 0.1493\n",
            "GBM: TEST RMSE=0.0803 | MAE=0.0539\n",
            "GBM: best CV RMSE = 0.1493\n",
            "GBM: TEST RMSE=0.0803 | MAE=0.0539\n",
            "HistGBM: best CV RMSE = 0.1487\n",
            "HistGBM: TEST RMSE=0.0795 | MAE=0.0540\n",
            "HistGBM: best CV RMSE = 0.1487\n",
            "HistGBM: TEST RMSE=0.0795 | MAE=0.0540\n",
            "XGBoost: best CV RMSE = 0.1509\n",
            "XGBoost: TEST RMSE=0.0804 | MAE=0.0542\n",
            "XGBoost: best CV RMSE = 0.1509\n",
            "XGBoost: TEST RMSE=0.0804 | MAE=0.0542\n",
            "LightGBM: best CV RMSE = 0.1496\n",
            "LightGBM: TEST RMSE=0.0809 | MAE=0.0548\n",
            "LightGBM: best CV RMSE = 0.1496\n",
            "LightGBM: TEST RMSE=0.0809 | MAE=0.0548\n",
            "CatBoost: best CV RMSE = 0.1497\n",
            "CatBoost: TEST RMSE=0.0778 | MAE=0.0526\n",
            "\n",
            "=== Feature set: top_all (56 features) ===\n",
            "CatBoost: best CV RMSE = 0.1497\n",
            "CatBoost: TEST RMSE=0.0778 | MAE=0.0526\n",
            "\n",
            "=== Feature set: top_all (56 features) ===\n",
            "AdaBoost: best CV RMSE = 0.1547\n",
            "AdaBoost: TEST RMSE=0.0944 | MAE=0.0688\n",
            "AdaBoost: best CV RMSE = 0.1547\n",
            "AdaBoost: TEST RMSE=0.0944 | MAE=0.0688\n",
            "GBM: best CV RMSE = 0.1492\n",
            "GBM: TEST RMSE=0.0805 | MAE=0.0545\n",
            "GBM: best CV RMSE = 0.1492\n",
            "GBM: TEST RMSE=0.0805 | MAE=0.0545\n",
            "HistGBM: best CV RMSE = 0.1487\n",
            "HistGBM: TEST RMSE=0.0795 | MAE=0.0540\n",
            "HistGBM: best CV RMSE = 0.1487\n",
            "HistGBM: TEST RMSE=0.0795 | MAE=0.0540\n",
            "XGBoost: best CV RMSE = 0.1508\n",
            "XGBoost: TEST RMSE=0.0805 | MAE=0.0542\n",
            "XGBoost: best CV RMSE = 0.1508\n",
            "XGBoost: TEST RMSE=0.0805 | MAE=0.0542\n",
            "LightGBM: best CV RMSE = 0.1495\n",
            "LightGBM: TEST RMSE=0.0809 | MAE=0.0548\n",
            "LightGBM: best CV RMSE = 0.1495\n",
            "LightGBM: TEST RMSE=0.0809 | MAE=0.0548\n",
            "CatBoost: best CV RMSE = 0.1501\n",
            "CatBoost: TEST RMSE=0.0803 | MAE=0.0543\n",
            "CatBoost: best CV RMSE = 0.1501\n",
            "CatBoost: TEST RMSE=0.0803 | MAE=0.0543\n"
          ]
        }
      ],
      "source": [
        "model_space = [\n",
        "    {\n",
        "        'name': 'AdaBoost',\n",
        "        'estimator': AdaBoostRegressor(\n",
        "            estimator=DecisionTreeRegressor(max_depth=3, random_state=SEED),\n",
        "            random_state=SEED,\n",
        "        ),\n",
        "        'grid': {\n",
        "            'n_estimators': [200, 400],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'loss': ['linear', 'square'],\n",
        "        },\n",
        "        'n_jobs': -1,\n",
        "    },\n",
        "    {\n",
        "        'name': 'GBM',\n",
        "        'estimator': GradientBoostingRegressor(random_state=SEED),\n",
        "        'grid': {\n",
        "            'n_estimators': [200, 500],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'max_depth': [3, 6],\n",
        "            'subsample': [0.6, 1.0],\n",
        "            'max_features': [None, 'sqrt'],\n",
        "        },\n",
        "        'n_jobs': -1,\n",
        "    },\n",
        "    {\n",
        "        'name': 'HistGBM',\n",
        "        'estimator': HistGradientBoostingRegressor(random_state=SEED),\n",
        "        'grid': {\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'max_depth': [None, 4],\n",
        "            'l2_regularization': [0.0, 0.5],\n",
        "            'min_samples_leaf': [10, 30],\n",
        "        },\n",
        "        'n_jobs': -1,\n",
        "    },\n",
        "    {\n",
        "        'name': 'XGBoost',\n",
        "        'estimator': XGBRegressor(\n",
        "            objective='reg:squarederror',\n",
        "            tree_method='hist',\n",
        "            random_state=SEED,\n",
        "            n_jobs=-1,\n",
        "            eval_metric='rmse',\n",
        "        ),\n",
        "        'grid': {\n",
        "            'n_estimators': [250, 500],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'max_depth': [3, 5],\n",
        "            'subsample': [0.7, 0.9],\n",
        "            'reg_lambda': [1.0, 5.0],\n",
        "        },\n",
        "        'n_jobs': 1,\n",
        "    },\n",
        "    {\n",
        "        'name': 'LightGBM',\n",
        "        'estimator': LGBMRegressor(\n",
        "            objective='regression',\n",
        "            random_state=SEED,\n",
        "            verbose=-1,\n",
        "            n_jobs=-1,\n",
        "            force_row_wise=True,\n",
        "        ),\n",
        "        'grid': {\n",
        "            'n_estimators': [200, 600],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'max_depth': [-1, 3],\n",
        "            'reg_lambda': [0.0, 1.0],\n",
        "        },\n",
        "        'n_jobs': -1,\n",
        "    },\n",
        "    {\n",
        "        'name': 'CatBoost',\n",
        "        'estimator': CatBoostRegressor(\n",
        "            loss_function='RMSE',\n",
        "            random_state=SEED,\n",
        "            allow_writing_files=False,\n",
        "            verbose=0,\n",
        "        ),\n",
        "        'grid': {\n",
        "            'depth': [3, 6],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'iterations': [300, 500],\n",
        "            'l2_leaf_reg': [3],\n",
        "        },\n",
        "        'n_jobs': 1,\n",
        "    },\n",
        " ]\n",
        "\n",
        "feature_set_estimators = {fs: {} for fs in feature_sets}\n",
        "best_models_map = {}\n",
        "best_estimators = {}\n",
        "\n",
        "for fs_name, fs_cols in feature_sets.items():\n",
        "    print(f\"\\n=== Feature set: {fs_name} ({len(fs_cols)} features) ===\")\n",
        "    X_tr = X_train_full[fs_cols]\n",
        "    X_te = X_test_full[fs_cols]\n",
        "    for spec in model_space:\n",
        "        grid = run_grid_search(spec['name'], spec['estimator'], spec['grid'], X_tr, y_train, n_jobs=spec['n_jobs'])\n",
        "        best_estimator = grid.best_estimator_\n",
        "        feature_set_estimators[fs_name][spec['name']] = best_estimator\n",
        "        cv_leaderboard.append({\n",
        "            'feature_set': fs_name,\n",
        "            'model': spec['name'],\n",
        "            'best_params': grid.best_params_,\n",
        "            'cv_rmse': -grid.best_score_,\n",
        "        })\n",
        "        eval_record = evaluate_on_test(spec['name'], best_estimator, X_te, y_test)\n",
        "        eval_record['feature_set'] = fs_name\n",
        "        test_performance.append(eval_record)\n",
        "        if (spec['name'] not in best_models_map) or (eval_record['rmse'] < best_models_map[spec['name']]['rmse']):\n",
        "            best_models_map[spec['name']] = {\n",
        "                'feature_set': fs_name,\n",
        "                'rmse': eval_record['rmse'],\n",
        "                'mae': eval_record['mae'],\n",
        "                'best_params': grid.best_params_,\n",
        "                'estimator': best_estimator,\n",
        "                'features': list(fs_cols),\n",
        "            }\n",
        "            best_estimators[spec['name']] = best_estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[XGBoostLSS] Feature set: top_20 (20 features)\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1489\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1489\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1490\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1490\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1485\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1485\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1499\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1499\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1494\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1494\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1514\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1514\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1502\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1502\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1518\n",
            "Best XGBoostLSS params (top_20): {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1485\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1518\n",
            "Best XGBoostLSS params (top_20): {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1485\n",
            "XGBoostLSS (top_20): TEST RMSE=0.0821 | MAE=0.0561\n",
            "\n",
            "[XGBoostLSS] Feature set: top_30 (30 features)\n",
            "XGBoostLSS (top_20): TEST RMSE=0.0821 | MAE=0.0561\n",
            "\n",
            "[XGBoostLSS] Feature set: top_30 (30 features)\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1490\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1490\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1487\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1487\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1488\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1488\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1487\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1487\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1497\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1497\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1513\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1513\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1493\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1493\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1510\n",
            "Best XGBoostLSS params (top_30): {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1487\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1510\n",
            "Best XGBoostLSS params (top_30): {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1487\n",
            "XGBoostLSS (top_30): TEST RMSE=0.0888 | MAE=0.0589\n",
            "\n",
            "[XGBoostLSS] Feature set: top_50 (50 features)\n",
            "XGBoostLSS (top_30): TEST RMSE=0.0888 | MAE=0.0589\n",
            "\n",
            "[XGBoostLSS] Feature set: top_50 (50 features)\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1487\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1487\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1486\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1486\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1491\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1491\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1492\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1492\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1498\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1498\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1520\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1520\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1497\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1497\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1524\n",
            "Best XGBoostLSS params (top_50): {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1486\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1524\n",
            "Best XGBoostLSS params (top_50): {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1486\n",
            "XGBoostLSS (top_50): TEST RMSE=0.0888 | MAE=0.0593\n",
            "\n",
            "[XGBoostLSS] Feature set: top_all (56 features)\n",
            "XGBoostLSS (top_50): TEST RMSE=0.0888 | MAE=0.0593\n",
            "\n",
            "[XGBoostLSS] Feature set: top_all (56 features)\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1488\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1488\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1492\n",
            "Params {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1492\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1489\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1489\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1494\n",
            "Params {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1494\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1500\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 3} -> CV RMSE 0.1500\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1519\n",
            "Params {'eta': 0.1, 'lambda': 1.0, 'max_depth': 5} -> CV RMSE 0.1519\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1498\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 3} -> CV RMSE 0.1498\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1525\n",
            "Best XGBoostLSS params (top_all): {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1488\n",
            "Params {'eta': 0.1, 'lambda': 3.0, 'max_depth': 5} -> CV RMSE 0.1525\n",
            "Best XGBoostLSS params (top_all): {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': 2000} | CV RMSE 0.1488\n",
            "XGBoostLSS (top_all): TEST RMSE=0.0843 | MAE=0.0568\n",
            "XGBoostLSS (top_all): TEST RMSE=0.0843 | MAE=0.0568\n"
          ]
        }
      ],
      "source": [
        "xgblss_param_grid = ParameterGrid({\n",
        "    'eta': [0.05, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'lambda': [1.0, 3.0],\n",
        "})\n",
        "\n",
        "for fs_name, fs_cols in feature_sets.items():\n",
        "    print(f\"\\n[XGBoostLSS] Feature set: {fs_name} ({len(fs_cols)} features)\")\n",
        "    X_tr = X_train_full[fs_cols]\n",
        "    X_te = X_test_full[fs_cols]\n",
        "    xgblss_trials = []\n",
        "    for params in xgblss_param_grid:\n",
        "        fold_scores = []\n",
        "        for fold_id, (train_idx, val_idx) in enumerate(tscv.split(X_tr), start=1):\n",
        "            dist = Gaussian()\n",
        "            model = XGBoostLSS(dist)\n",
        "            dtrain = DMatrix(X_tr.iloc[train_idx], label=y_train.iloc[train_idx])\n",
        "            dval = DMatrix(X_tr.iloc[val_idx], label=y_train.iloc[val_idx])\n",
        "            evals = [(dtrain, 'train'), (dval, 'validation')]\n",
        "            model.train(\n",
        "                params={**params, 'booster': 'gbtree', 'tree_method': 'hist', 'seed': SEED},\n",
        "                dtrain=dtrain,\n",
        "                num_boost_round=600,\n",
        "                evals=evals,\n",
        "                early_stopping_rounds=50,\n",
        "                verbose_eval=False,\n",
        "            )\n",
        "            pred_df = model.predict(dval, pred_type='parameters')\n",
        "            rmse = float(np.sqrt(mean_squared_error(y_train.iloc[val_idx], pred_df['loc'].values)))\n",
        "            fold_scores.append(rmse)\n",
        "        mean_rmse = float(np.mean(fold_scores))\n",
        "        xgblss_trials.append({'params': params, 'cv_rmse': mean_rmse})\n",
        "        print(f\"Params {params} -> CV RMSE {mean_rmse:.4f}\")\n",
        "    best_xgblss = min(xgblss_trials, key=lambda row: row['cv_rmse'])\n",
        "    best_params = {**best_xgblss['params'], 'booster': 'gbtree', 'tree_method': 'hist', 'seed': SEED}\n",
        "    print(\n",
        "        f\"Best XGBoostLSS params ({fs_name}): {best_params} | CV RMSE {best_xgblss['cv_rmse']:.4f}\")\n",
        "    dist = Gaussian()\n",
        "    xgblss_model = XGBoostLSS(dist)\n",
        "    dtrain_full = DMatrix(X_tr, label=y_train)\n",
        "    xgblss_model.train(\n",
        "        params=best_params,\n",
        "        dtrain=dtrain_full,\n",
        "        num_boost_round=600,\n",
        "        evals=None,\n",
        "        verbose_eval=False,\n",
        "        early_stopping_rounds=None,\n",
        "    )\n",
        "    feature_set_estimators[fs_name]['XGBoostLSS'] = xgblss_model\n",
        "    cv_leaderboard.append({\n",
        "        'feature_set': fs_name,\n",
        "        'model': 'XGBoostLSS',\n",
        "        'best_params': best_params,\n",
        "        'cv_rmse': best_xgblss['cv_rmse'],\n",
        "    })\n",
        "    dtest = DMatrix(X_te, label=y_test)\n",
        "    preds = xgblss_model.predict(dtest, pred_type='parameters')['loc'].values\n",
        "    rmse = float(np.sqrt(mean_squared_error(y_test, preds)))\n",
        "    mae = float(mean_absolute_error(y_test, preds))\n",
        "    eval_record = {'model': 'XGBoostLSS', 'rmse': rmse, 'mae': mae, 'feature_set': fs_name}\n",
        "    test_performance.append(eval_record)\n",
        "    if ('XGBoostLSS' not in best_models_map) or (rmse < best_models_map['XGBoostLSS']['rmse']):\n",
        "        best_models_map['XGBoostLSS'] = {\n",
        "            'feature_set': fs_name,\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'best_params': best_params,\n",
        "            'estimator': xgblss_model,\n",
        "            'features': list(fs_cols),\n",
        "        }\n",
        "        best_estimators['XGBoostLSS'] = xgblss_model\n",
        "    print(f\"XGBoostLSS ({fs_name}): TEST RMSE={rmse:.4f} | MAE={mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>feature_set</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>best_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>top_50</td>\n",
              "      <td>0.077766</td>\n",
              "      <td>0.052639</td>\n",
              "      <td>{'depth': 6, 'iterations': 300, 'l2_leaf_reg':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HistGBM</td>\n",
              "      <td>top_50</td>\n",
              "      <td>0.079462</td>\n",
              "      <td>0.054048</td>\n",
              "      <td>{'l2_regularization': 0.0, 'learning_rate': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>top_20</td>\n",
              "      <td>0.079501</td>\n",
              "      <td>0.053989</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GBM</td>\n",
              "      <td>top_20</td>\n",
              "      <td>0.079961</td>\n",
              "      <td>0.054205</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>top_20</td>\n",
              "      <td>0.080704</td>\n",
              "      <td>0.055303</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>top_20</td>\n",
              "      <td>0.082065</td>\n",
              "      <td>0.056052</td>\n",
              "      <td>{'eta': 0.05, 'lambda': 3.0, 'max_depth': 3, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>top_30</td>\n",
              "      <td>0.091576</td>\n",
              "      <td>0.066001</td>\n",
              "      <td>{'learning_rate': 0.05, 'loss': 'linear', 'n_e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        model feature_set      rmse       mae                                        best_params\n",
              "0    CatBoost      top_50  0.077766  0.052639  {'depth': 6, 'iterations': 300, 'l2_leaf_reg':...\n",
              "1     HistGBM      top_50  0.079462  0.054048  {'l2_regularization': 0.0, 'learning_rate': 0....\n",
              "2     XGBoost      top_20  0.079501  0.053989  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "3         GBM      top_20  0.079961  0.054205  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...\n",
              "4    LightGBM      top_20  0.080704  0.055303  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "5  XGBoostLSS      top_20  0.082065  0.056052  {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3, '...\n",
              "6    AdaBoost      top_30  0.091576  0.066001  {'learning_rate': 0.05, 'loss': 'linear', 'n_e..."
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_feature_set_summary = (\n",
        "    pd.DataFrame([\n",
        "        {\n",
        "            'model': model,\n",
        "            'feature_set': payload['feature_set'],\n",
        "            'rmse': payload['rmse'],\n",
        "            'mae': payload['mae'],\n",
        "            'best_params': payload['best_params'],\n",
        "        }\n",
        "        for model, payload in best_models_map.items()\n",
        "    ])\n",
        "    .sort_values('rmse')\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "best_feature_set_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>feature_set</th>\n",
              "      <th>model</th>\n",
              "      <th>cv_rmse</th>\n",
              "      <th>best_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>top_20</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.148454</td>\n",
              "      <td>{'eta': 0.05, 'lambda': 3.0, 'max_depth': 3, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>top_30</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.148601</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>top_50</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.148637</td>\n",
              "      <td>{'eta': 0.05, 'lambda': 1.0, 'max_depth': 5, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>top_30</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.148658</td>\n",
              "      <td>{'eta': 0.05, 'lambda': 3.0, 'max_depth': 5, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>top_all</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.148676</td>\n",
              "      <td>{'l2_regularization': 0.0, 'learning_rate': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>top_50</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.148677</td>\n",
              "      <td>{'l2_regularization': 0.0, 'learning_rate': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>top_all</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.148762</td>\n",
              "      <td>{'eta': 0.05, 'lambda': 1.0, 'max_depth': 3, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>top_20</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.148823</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>top_20</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.148824</td>\n",
              "      <td>{'l2_regularization': 0.0, 'learning_rate': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>top_20</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.148824</td>\n",
              "      <td>{'l2_regularization': 0.0, 'learning_rate': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>top_30</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.148859</td>\n",
              "      <td>{'l2_regularization': 0.5, 'learning_rate': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>top_20</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.149124</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>top_20</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.149124</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>top_all</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.149217</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>top_50</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.149322</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>top_all</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.149514</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>top_50</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.149586</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>top_50</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.149673</td>\n",
              "      <td>{'depth': 6, 'iterations': 300, 'l2_leaf_reg':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>top_30</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.149736</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>top_20</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.150064</td>\n",
              "      <td>{'depth': 6, 'iterations': 300, 'l2_leaf_reg':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>top_all</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.150083</td>\n",
              "      <td>{'depth': 3, 'iterations': 300, 'l2_leaf_reg':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>top_30</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.150474</td>\n",
              "      <td>{'depth': 3, 'iterations': 300, 'l2_leaf_reg':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>top_all</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.150806</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>top_50</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.150870</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>top_20</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.150906</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>top_20</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.150906</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>top_30</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.151305</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>top_20</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.153056</td>\n",
              "      <td>{'colsample_bytree': 0.7, 'learning_rate': 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>top_all</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.154744</td>\n",
              "      <td>{'learning_rate': 0.05, 'loss': 'linear', 'n_e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>top_50</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.155198</td>\n",
              "      <td>{'learning_rate': 0.05, 'loss': 'linear', 'n_e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>top_30</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.155408</td>\n",
              "      <td>{'learning_rate': 0.05, 'loss': 'linear', 'n_e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>top_20</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.155764</td>\n",
              "      <td>{'learning_rate': 0.05, 'loss': 'linear', 'n_e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>top_20</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.155764</td>\n",
              "      <td>{'learning_rate': 0.05, 'loss': 'linear', 'n_e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    rank feature_set       model   cv_rmse                                        best_params\n",
              "0      1      top_20  XGBoostLSS  0.148454  {'eta': 0.05, 'lambda': 3.0, 'max_depth': 3, '...\n",
              "1      2      top_30         GBM  0.148601  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...\n",
              "2      3      top_50  XGBoostLSS  0.148637  {'eta': 0.05, 'lambda': 1.0, 'max_depth': 5, '...\n",
              "3      4      top_30  XGBoostLSS  0.148658  {'eta': 0.05, 'lambda': 3.0, 'max_depth': 5, '...\n",
              "4      5     top_all     HistGBM  0.148676  {'l2_regularization': 0.0, 'learning_rate': 0....\n",
              "5      6      top_50     HistGBM  0.148677  {'l2_regularization': 0.0, 'learning_rate': 0....\n",
              "6      7     top_all  XGBoostLSS  0.148762  {'eta': 0.05, 'lambda': 1.0, 'max_depth': 3, '...\n",
              "7      8      top_20    LightGBM  0.148823  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "8      9      top_20     HistGBM  0.148824  {'l2_regularization': 0.0, 'learning_rate': 0....\n",
              "9     10      top_20     HistGBM  0.148824  {'l2_regularization': 0.0, 'learning_rate': 0....\n",
              "10    11      top_30     HistGBM  0.148859  {'l2_regularization': 0.5, 'learning_rate': 0....\n",
              "11    12      top_20         GBM  0.149124  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...\n",
              "12    13      top_20         GBM  0.149124  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...\n",
              "13    14     top_all         GBM  0.149217  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...\n",
              "14    15      top_50         GBM  0.149322  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...\n",
              "15    16     top_all    LightGBM  0.149514  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "16    17      top_50    LightGBM  0.149586  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "17    18      top_50    CatBoost  0.149673  {'depth': 6, 'iterations': 300, 'l2_leaf_reg':...\n",
              "18    19      top_30    LightGBM  0.149736  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "19    20      top_20    CatBoost  0.150064  {'depth': 6, 'iterations': 300, 'l2_leaf_reg':...\n",
              "20    21     top_all    CatBoost  0.150083  {'depth': 3, 'iterations': 300, 'l2_leaf_reg':...\n",
              "21    22      top_30    CatBoost  0.150474  {'depth': 3, 'iterations': 300, 'l2_leaf_reg':...\n",
              "22    23     top_all     XGBoost  0.150806  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "23    24      top_50     XGBoost  0.150870  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "24    25      top_20     XGBoost  0.150906  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "25    26      top_20     XGBoost  0.150906  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "26    27      top_30     XGBoost  0.151305  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...\n",
              "27    28      top_20    LightGBM  0.153056  {'colsample_bytree': 0.7, 'learning_rate': 0.0...\n",
              "28    29     top_all    AdaBoost  0.154744  {'learning_rate': 0.05, 'loss': 'linear', 'n_e...\n",
              "29    30      top_50    AdaBoost  0.155198  {'learning_rate': 0.05, 'loss': 'linear', 'n_e...\n",
              "30    31      top_30    AdaBoost  0.155408  {'learning_rate': 0.05, 'loss': 'linear', 'n_e...\n",
              "31    32      top_20    AdaBoost  0.155764  {'learning_rate': 0.05, 'loss': 'linear', 'n_e...\n",
              "32    33      top_20    AdaBoost  0.155764  {'learning_rate': 0.05, 'loss': 'linear', 'n_e..."
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_df = (\n",
        "    pd.DataFrame(cv_leaderboard)\n",
        "    .sort_values('cv_rmse')\n",
        "    .reset_index(drop=True)\n",
        "    .assign(rank=lambda df: df.index + 1)\n",
        "    [['rank', 'feature_set', 'model', 'cv_rmse', 'best_params']]\n",
        " )\n",
        "cv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>feature_set</th>\n",
              "      <th>model</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>top_50</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.077766</td>\n",
              "      <td>0.052639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>top_20</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.078598</td>\n",
              "      <td>0.053631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>top_50</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.079462</td>\n",
              "      <td>0.054048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>top_all</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.079462</td>\n",
              "      <td>0.054048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>top_20</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.079501</td>\n",
              "      <td>0.053989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>top_20</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.079501</td>\n",
              "      <td>0.053989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>top_30</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.079770</td>\n",
              "      <td>0.054459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>top_20</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.079961</td>\n",
              "      <td>0.054205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>top_20</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.079961</td>\n",
              "      <td>0.054205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>top_50</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.080262</td>\n",
              "      <td>0.053862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>top_20</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.080265</td>\n",
              "      <td>0.054557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>top_20</td>\n",
              "      <td>HistGBM</td>\n",
              "      <td>0.080265</td>\n",
              "      <td>0.054557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>top_all</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.080324</td>\n",
              "      <td>0.054251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>top_50</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.080368</td>\n",
              "      <td>0.054225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>top_30</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.080426</td>\n",
              "      <td>0.054108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>top_30</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.080478</td>\n",
              "      <td>0.054333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>top_all</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.080491</td>\n",
              "      <td>0.054239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>top_all</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.080501</td>\n",
              "      <td>0.054522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>top_30</td>\n",
              "      <td>GBM</td>\n",
              "      <td>0.080593</td>\n",
              "      <td>0.054427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>top_20</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.080704</td>\n",
              "      <td>0.055303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>top_50</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.080866</td>\n",
              "      <td>0.054767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>top_all</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.080866</td>\n",
              "      <td>0.054767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>top_30</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.080983</td>\n",
              "      <td>0.055504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>top_20</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.082065</td>\n",
              "      <td>0.056052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>top_all</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.084346</td>\n",
              "      <td>0.056760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>top_20</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.086884</td>\n",
              "      <td>0.060614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>top_50</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.088794</td>\n",
              "      <td>0.059269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>top_30</td>\n",
              "      <td>XGBoostLSS</td>\n",
              "      <td>0.088812</td>\n",
              "      <td>0.058914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>top_30</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.091576</td>\n",
              "      <td>0.066001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>top_20</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.092544</td>\n",
              "      <td>0.067771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>top_20</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.092544</td>\n",
              "      <td>0.067771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>top_50</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.094304</td>\n",
              "      <td>0.069590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>top_all</td>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.094386</td>\n",
              "      <td>0.068806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    rank feature_set       model      rmse       mae\n",
              "0      1      top_50    CatBoost  0.077766  0.052639\n",
              "1      2      top_20    CatBoost  0.078598  0.053631\n",
              "2      3      top_50     HistGBM  0.079462  0.054048\n",
              "3      4     top_all     HistGBM  0.079462  0.054048\n",
              "4      5      top_20     XGBoost  0.079501  0.053989\n",
              "5      6      top_20     XGBoost  0.079501  0.053989\n",
              "6      7      top_30     HistGBM  0.079770  0.054459\n",
              "7      8      top_20         GBM  0.079961  0.054205\n",
              "8      9      top_20         GBM  0.079961  0.054205\n",
              "9     10      top_50         GBM  0.080262  0.053862\n",
              "10    11      top_20     HistGBM  0.080265  0.054557\n",
              "11    12      top_20     HistGBM  0.080265  0.054557\n",
              "12    13     top_all    CatBoost  0.080324  0.054251\n",
              "13    14      top_50     XGBoost  0.080368  0.054225\n",
              "14    15      top_30    CatBoost  0.080426  0.054108\n",
              "15    16      top_30     XGBoost  0.080478  0.054333\n",
              "16    17     top_all     XGBoost  0.080491  0.054239\n",
              "17    18     top_all         GBM  0.080501  0.054522\n",
              "18    19      top_30         GBM  0.080593  0.054427\n",
              "19    20      top_20    LightGBM  0.080704  0.055303\n",
              "20    21      top_50    LightGBM  0.080866  0.054767\n",
              "21    22     top_all    LightGBM  0.080866  0.054767\n",
              "22    23      top_30    LightGBM  0.080983  0.055504\n",
              "23    24      top_20  XGBoostLSS  0.082065  0.056052\n",
              "24    25     top_all  XGBoostLSS  0.084346  0.056760\n",
              "25    26      top_20    LightGBM  0.086884  0.060614\n",
              "26    27      top_50  XGBoostLSS  0.088794  0.059269\n",
              "27    28      top_30  XGBoostLSS  0.088812  0.058914\n",
              "28    29      top_30    AdaBoost  0.091576  0.066001\n",
              "29    30      top_20    AdaBoost  0.092544  0.067771\n",
              "30    31      top_20    AdaBoost  0.092544  0.067771\n",
              "31    32      top_50    AdaBoost  0.094304  0.069590\n",
              "32    33     top_all    AdaBoost  0.094386  0.068806"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = (\n",
        "    pd.DataFrame(test_performance)\n",
        "    .sort_values('rmse')\n",
        "    .reset_index(drop=True)\n",
        "    .assign(rank=lambda df: df.index + 1)\n",
        "    [['rank', 'feature_set', 'model', 'rmse', 'mae']]\n",
        " )\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature-set level performance\n",
        "Averaging RMSE/MAE across models makes it easier to see whether deeper feature pools are consistently helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
              "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_set</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>top_20</th>\n",
              "      <td>0.082733</td>\n",
              "      <td>0.005044</td>\n",
              "      <td>0.057220</td>\n",
              "      <td>0.005269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_all</th>\n",
              "      <td>0.082911</td>\n",
              "      <td>0.005294</td>\n",
              "      <td>0.056770</td>\n",
              "      <td>0.005387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_50</th>\n",
              "      <td>0.083117</td>\n",
              "      <td>0.006057</td>\n",
              "      <td>0.056914</td>\n",
              "      <td>0.005970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_30</th>\n",
              "      <td>0.083234</td>\n",
              "      <td>0.004835</td>\n",
              "      <td>0.056821</td>\n",
              "      <td>0.004383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 rmse                 mae          \n",
              "                 mean       std      mean       std\n",
              "feature_set                                        \n",
              "top_20       0.082733  0.005044  0.057220  0.005269\n",
              "top_all      0.082911  0.005294  0.056770  0.005387\n",
              "top_50       0.083117  0.006057  0.056914  0.005970\n",
              "top_30       0.083234  0.004835  0.056821  0.004383"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_set_performance = (\n",
        "    test_df.groupby('feature_set')[['rmse', 'mae']]\n",
        "    .agg(['mean', 'std'])\n",
        "    .sort_values(('rmse', 'mean'))\n",
        ")\n",
        "feature_set_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'AdaBoost': '../models/adaboost_gradient_model.sav',\n",
              " 'GBM': '../models/gbm_gradient_model.sav',\n",
              " 'HistGBM': '../models/histgbm_gradient_model.sav',\n",
              " 'XGBoost': '../models/xgboost_gradient_model.sav',\n",
              " 'LightGBM': '../models/lightgbm_gradient_model.sav',\n",
              " 'CatBoost': '../models/catboost_gradient_model.sav',\n",
              " 'XGBoostLSS': '../models/xgboostlss_gradient_model.sav'}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_paths = {}\n",
        "for name, estimator in best_estimators.items():\n",
        "    filename = f\"{name.lower().replace(' ', '_')}_gradient_model.sav\"\n",
        "    path = MODEL_DIR / filename\n",
        "    if name == 'XGBoostLSS':\n",
        "        estimator.save_model(path)\n",
        "    else:\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(estimator, f)\n",
        "    model_paths[name] = path.as_posix()\n",
        "model_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.barplot(data=test_df, x='model', y='rmse', palette='viridis')\n",
        "plt.title('Test RMSE by Gradient Boosting Model')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xlabel('Model')\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
